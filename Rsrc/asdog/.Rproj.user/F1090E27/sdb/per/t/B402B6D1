{
    "collab_server" : "",
    "contents" : "#!/usr/bin/env Rscript\n#\n# aspup main script\n#\n#\n\n# -------------------------------------------------\n# compute % GC of string\n#\npergc <- function(s, offset=0, winsize=nchar(s)) {\n  s <- substr(s, start=offset, stop=offset+winsize)\n  length(lx.strchr(s, \"GC\"))/nchar(s)\n}\n\n# -------------------------------------------------\n# gam GC model\n# (simplified version of asdog GC model)\n#\ngam.model <- function(gc, cov, N=100,\n                      base.quant=0.01,\n                      trim.quant=c(0.02, 0.95)) {\n\n  mod <- list(gc=gc, cov=cov, mcov=median(cov), N=N)\n\n  # aggregate\n  mod$mean <- aggregate(cov, list(gc=round(gc*N)), FUN=median)\n  colnames(mod$mean) <- c(\"gc\", \"cov\")\n\n  # baseline adjustment\n  #\n  baseline <- if (is.na(base.quant)) 1 else quantile(cov, base.quant, na.rm=T)\n  cov <- c(baseline, baseline, mod$mean$cov)\n  gc  <- c(0, N, mod$mean$gc)\n  \n  # make gam model\n  #\n  mod$gam <- gam(cov ~ s(gc))\n\n  # prediction vector \n  #\n  mod$pvec <- predict(mod$gam, list(gc=seq.int(0, N)))\n  mod$pvec[mod$pvec <= baseline] <- baseline\n  \n  # trim low and high gc\n  #\n  if (! is.null(trim.quant)) {\n    trim <- quantile(mod$gc, trim.quant, na.rm=T)\n    bnds <- round(trim*N)\n    mod$pvec[1:bnds[1]] <- mod$pvec[bnds[1]]\n    mod$pvec[bnds[2]:length(mod$pvec)] <- mod$pvec[bnds[2]]\n  }\n  \n  # remove outliers (may occur if span is too small)\n  #\n  #   outl <- 5*median(mod$pvec, na.rm=T)\n  #   mod$pvec[mod$pvec >= outl] <- outl\n  \n  mod\n}\n\n# -------------------------------------------------\n# gam GC model predictor\n#\ngam.predict <- function(mod, gc) as.vector(mod$pvec[round(gc*mod$N)+1])\n\n# -------------------------------------------------\n# log2 ratio\n#\nlog.ratio <- function(x, y, EPS=1e-6) {\n  x[abs(x)<=EPS] <- EPS\n  y[abs(y)<=EPS] <- EPS\n  log(x/y, base=2)\n}\n\n# -------------------------------------------------\n# local plot : plot GC gam model\n#\nplot.gcmodel <- function(mod, xlim=c(0.2,0.8), ylim=c(0,2), ...) {\n  \n  lx.plot(mod$gc, mod$cov/mod$mcov,\n          xlim=xlim,\n          ylim=ylim,\n          xlab=\"%GC\", ylab=\"rel. cov.\",\n          ...)\n  \n  points(mod$mean$gc/mod$N, mod$mean$cov/mod$mcov, pch=19, cex=0.8, col=4)\n  points(mod$mean$gc/mod$N, mod$mean$cov/mod$mcov, pch=1, cex=0.8, col=7)\n  lines(seq.int(0, 1, 1/mod$N), mod$pvec/mod$mcov, col=2, lwd=3)\n  abline(h=1, col=3)\n  abline(v=mean(mod$gc), col=3)\n\n  invisible()\n}\n\n# -------------------------------------------------\n# local plot : cn profile\n#\nplot.profile <- function(x, y, fun=plot, chrs=NULL, hline=1,\n                         ylim=NULL, cex=0.05, alpha=0.2,\n                         xlab=\"pos\", ylab=\"Y\", ...) {\n  \n  if (missing(y)) {\n    y <- x\n    x <- seq_along(y)\n  }\n  \n  if (is.null(ylim)) {\n    ylim <- quantile(y, c(0.01, 0.99), na.rm=T)\n  }\n  \n  below <- y<=ylim[1]\n  above <- y>=ylim[2]\n  y[below] <- ylim[1]\n  y[above] <- ylim[2]\n  \n  col <- lx.color.alpha(ifelse(above|below, 6, 1), alpha)\n  \n  fun(x, y, ylim=ylim, cex=cex, \n       xlab=xlab, ylab=ylab,\n       col=col, ...)\n\n  abline(h=hline, col=4)\n  \n  if (! is.null(chrs)) {\n    rle <- rle(chrs)\n    gx <- x[cumsum(rle$lengths)]\n    abline(v=gx, col=4)\n    text(gx, ylim[2], labels=rle$values, cex=0.5, pos=2, off=0.1, col=4)\n  }\n  \n  invisible()\n}\n\n# -------------------------------------------------\n# get segment statistics\n#\nstat.segments <- function(seg, pos, data, what=c(\"rc\", \"af\")) {\n  \n  what <- match.arg(what)\n  \n  if (what == \"af\") data <- abs(data-0.5)+0.5 # fold af\n  \n  res <- lapply(seq_len(nrow(seg)), function(i) {\n    row   <- seg[i,] # 'apply' sucks\n    ifrom <- lx.findInterval(row$from, pos)\n    ito   <- lx.findInterval(row$to, pos)\n    ilen  <- ito - ifrom + 1\n    seg.data <- as.vector(data[seq.int(ifrom, ito)])\n    med  <- median(seg.data)\n    sd   <- if (ilen > 1) sd(seg.data) else 0\n    mad  <- mad(seg.data)\n    if (mad == 0) mad <- sd\n    if (what == \"af\") {\n      cor <- asdog.unfold(med, sd, type=\"median\")$solution\n      med <- cor$mu\n      mad <- cor$sd\n    }\n    ref  <- row[, what]\n    zscor <- if (med == ref) 0 else (med - ref)/mad\n    pval  <- 2*pnorm(-abs(zscor)) # two-sided\n    list(nb.mark=ilen, med=med, mad=mad, zscor=zscor, pval=pval)\n  })\n  \n  as.data.frame(apply(do.call(rbind, res), 2, unlist))\n}\n\n\n# =========================\n# main\n# =========================\n\nif (FALSE) {\n\nlibrary(asdog)\n\n#\n# parameters (should be handled by asdog.parameters)\n#\n  \nPCNV.VERSION = \"1.0\"        # version number\nCOV.FUN = \"median\"          # cover collect function\nCOV.MIN = 5                 # minimum reads for normal cover\nCOV.QUANT = c(0.02, 0.98)   # extreme cover quantiles\nCOF.QUANT = 0.95            # var. coeff quantile\n#GC.QUANT = c(0.005, 0.995)  # trim quantiles for GC model\nGC.QUANT = NULL             # trim quantiles for GC model\nRATIO.EPS  = 1e-6           # epsilon value for ratio\nSNP.SOURCE = \"hapmap\"       # source of SNPs (paired or hapmap)\nBAF.THRESH = 0.8            # lower threshold for BAF filtering\nBAF.SD = 4                  # sd factor for BAF filtering\nRRC.MAX = 4                 # rrc max\nMIN.SEGSIZE = 1e6           # minimum segment size (in b)\nBCP.P0 = 1e-10              # BCP proba\nWEIGHT.QUANT = 0.25         # lower quantile for segment weights\nRANGE.A = c(0, 1, 0.05)     # contamination range and step for fit\nRANGE.Q = c(1, 8, 0.05)     # ploidy range and step for fit\nFIT.GAMMA0 = 1              # fit gamma parameter\nFIT.RHO = 0.5               # fit rho parameter\nCN.MAX = 20                 # copy number max\nHMM.TAU = 1e-50             # HMM transition proba\n\n\nlx.options(use.threads=T)\n\n#\n# backbone Hapmap SNPs\n#\n\nSFIL = \"data/backbone.hapmap.snp.rds\"\n\n#\n# test data\n#\n\n# ok\ntfil = \"/TmpStorage/prof2data/P_01-2129_refined_alignement.recalibrated.data.rds\"\n\n# traines\n# tfil = \"/TmpStorage/prof2data/P_01-2162_refined_alignement.recalibrated.data.rds\"\n\n# multiple normal - ok\n#\nnfil = c(\"/TmpStorage/prof2data/P_01-2129_constit_refined_alignement.recalibrated.data.rds\",\n         \"/TmpStorage/prof2data/P_01-2162_constit_refined_alignement.recalibrated.data.rds\")\n\n# run2\nnfil = c(\"/TmpStorage/prof2data/Run2_Normal_6950_recalibrated_alignment_human_g1k_v37.data.rds\",\n         \"/TmpStorage/prof2data/Run2_Normal_7471_recalibrated_alignment_human_g1k_v37.data.rds\")\ntfil = \"/TmpStorage/prof2data/Run2_TumProf1_D170965_recalibrated_alignment_human_g1k_v37.data.rds\"\ntfil = \"/TmpStorage/prof2data/Run2_TumProf2_D171171_recalibrated_alignment_human_g1k_v37.data.rds\"\n\n\n# ---------------------\n# banner\n#\n\nlx.out(\"--------------------------------------------\", with.mem=T)\nlx.out(\"AsPup version \", PCNV.VERSION)\nlx.out(\"--------------------------------------------\")\n\n# ---------------------\n# read data\n#\n\nlx.out(\"reading \", length(nfil), \" control data\")\n\nndat <- lapply(nfil, function(f) {\n          lx.out(\"reading control data: \", f)\n          readRDS(f)\n        })\n\nlx.out(\"reading tumour data\", tfil)\ntdat <- readRDS(tfil)\n\n# @todo: check sizes and NA\n\n# FIXME\ntdat$header$sizes <- sapply(tdat$header$seq, function(x) x$size)\n\n# collect pos, len and GC\n\nlx.out(\"collecting GC\")\n\ndf <- data.frame(tdat$beds)\n\ndf$indx <- seq.int(nrow(df))\n\ndf$len <- df$to - df$from + 1\n\ndf$gc <- sapply(tdat$seq, pergc)\n\n# collect cover\n\nlx.out(\"collecting cover with: \", COV.FUN)\n\nncov <- lx.lapply(ndat, function(d) sapply(d$baf, function(x, fun) \n  fun(rowSums(x)), fun=get(COV.FUN)))\n\ntcov <- sapply(tdat$baf, function(x, fun) fun(rowSums(x)), fun=get(COV.FUN))\n\n# ---------------------\n# filter low and high counts\n#\n\nrefmean <- mean(sapply(ncov, mean))\n\nmcov  <- lapply(ncov, function(x) x*refmean/mean(x))\nmcov  <- rowMeans(do.call(cbind, mcov))\nquant <- pmax(quantile(mcov, COV.QUANT), c(COV.MIN, 0))\n\nnok  <- (mcov > quant[1]) & (mcov < quant[2])\n\nlx.out(\"lowcount filter: \", sum(nok), \" data points kepts on \", length(nok), \n       \" (\", round(sum(nok)*100/length(nok), 1), \"%)\")\n\nncov <- lapply(ncov, function(x) x[nok])\ntcov <- tcov[nok]\ndf <- df[nok,]\n\n# ---------------------\n# rescale by median => normalize by library depth\n#\n\nncov <- lapply(ncov, function(x) x / median(x))\ntcov <- tcov / median(tcov)\n\n# ---------------------\n# remove variable probes\n#\n\nif (length(ncov) > 1) {\n  \n  mcov <- do.call(cbind, ncov)\n  mcof <- apply(mcov, 1, function(x) sd(x)/mean(x))\n  nok <- mcof <= quantile(mcof, COF.QUANT)\n  \n  lx.out(\"ref var. coef. filter: \", sum(nok), \" data points kepts on \", length(nok), \n         \" (\", round(sum(nok)*100/length(nok), 1), \"%)\")\n\n  ncov <- lapply(ncov, function(x) x[nok])\n  tcov <- tcov[nok]\n  df <- df[nok,]\n}\n\n# ---------------------\n# mean of reference\n#\n\nmcov <- rowMeans(do.call(cbind, ncov))\n\n# ---------------------\n# probe length correction\n#\n\nmod.len <- lm(mcov ~ df$len)\ncor.len <- predict(mod.len)\n\nncov <- lapply(ncov, function(x) x / cor.len)\nmcov <- mcov / cor.len\ntcov <- tcov / cor.len\n\n# ---------------------\n# GC correction\n#\n\nnmod.gc <- gam.model(df$gc, mcov, trim.quant=GC.QUANT)\n\nncor.gc <- gam.predict(nmod.gc, df$gc)\n\ntmod.gc <- gam.model(df$gc, tcov, trim.quant=GC.QUANT)\n\ntcor.gc <- gam.predict(tmod.gc, df$gc)\n\nncor.gc[ncor.gc < RATIO.EPS] <- RATIO.EPS\ntcor.gc[tcor.gc < RATIO.EPS] <- RATIO.EPS\n\nncov <- lapply(ncov, function(x) x / ncor.gc)\nmcov <- mcov / ncor.gc\ntcov <- tcov / tcor.gc\n\n# ---------------------\n# final normalisation - center on median\n#\n\nncov <- lapply(ncov, function(x) x / median(x))\nmcov <- mcov / median(mcov)\ntcov <- tcov / median(tcov)\n\n# ---------------------\n# get BAF\n#\n\nif (SNP.SOURCE == \"hapmap\") {\n  \n  sfil <- SFIL\n  \n  if (! file.exists(sfil)) {\n    \n    lx.out(\"recovering hapmap SNPs\")\n    \n    # get Hapmap SNP in probes\n    \n    snp <- readRDS(lx.system.file(\"data/HapMap.hg19.snp.full.rds\", package=\"asdog\"))\n    chr <- basta.name2index(tdat, as.character(snp$CHROM))\n    clocs.snp <- clocations(cbind(chr, snp$POS, snp$POS))\n    coords.snp <- clocs2coords(tdat, clocs.snp)\n    int.snp <- intervals::Intervals(coords.snp)\n    \n    coords.bed <- clocs2coords(tdat, tdat$beds)\n    int.bed <- intervals::Intervals(coords.bed)\n    \n    int.inter <- intervals::interval_intersection(int.snp, int.bed)\n    indx.inter <- findInterval(int.inter[,1], int.snp[,1])\n    jndx.inter <- (findInterval(int.inter[,1], as.vector(t(int.bed)))+1)/2\n    \n    snp.probes <- snp[indx.inter,]\n    snp.probes$PROBE <- jndx.inter\n    snp.probes$COORD <- coords.snp[indx.inter,1]\n    \n    lx.out(\"saving hapmap SNPs in \", sfil)\n    \n    saveRDS(snp.probes, sfil)\n  }\n  \n  lx.out(\"recovering SNPs\")\n  \n  snp <- readRDS(sfil)\n  \n} else {\n  \n  # get heterozygous positions in paired normal\n  # paired normal is assumed to be at ndat[1]\n  \n  pndat <- ndat[[1]]\n\n  coord.all <- clocs2coords(pndat, pndat$beds)\n  coord <- unlist(apply(coord.all, 1, function(x) x[1]:x[2]), use.names=F)\n\n  pnbaf <- do.call(rbind, pndat$baf)\n  pnref <- strsplit(do.call(paste0, pndat$seq), \"\")[[1]]\n  pnrow <- rowSums(pnbaf)\n  pnraf <- lx.rowMaxs(pnbaf)/pnrow\n  pnbok <- (! is.na(pnrow)) & (pnrow > 10) & (abs(pnraf-0.5) < 0.1)\n  \n  coord <- coord[pnbok]\n  pnbaf <- pnbaf[pnbok,]\n  pnref <- pnref[pnbok]\n  \n  pnalt <- pnbaf\n  pnalt[cbind(seq_along(pnref), match(pnref, colnames(pnbaf)))] <- 0\n  pnalt <- colnames(pnalt)[lx.rowMaxs(pnalt, what=\"index\")]\n  \n  clocs <- coords2clocs(pndat, coord)\n  iprob <- findInterval(coord, coord.all[,1])\n  \n  snp <- data.frame(CHROM=clocs[,1], POS=clocs[,2], ID=\"none\",\n                    REF=pnref, ALT=pnalt, AF=1.0, \n                    PROBE=iprob, COORD=coord)\n}\n  \n# recover baf at SNP positions\n\ncoord <- clocs2coords(tdat, tdat$beds)\ncoord <- unlist(apply(coord, 1, function(x) x[1]:x[2]), use.names=F)\nspos  <- findInterval(snp$COORD, coord)\nsbaf  <- do.call(rbind, tdat$baf)[spos,]\n\nindx <- cbind(seq_along(spos), match(snp$ALT, colnames(sbaf)))\ntbaf <- sbaf[indx]/(rowSums(sbaf)+RATIO.EPS)\n\n# remove homozygous positions\n\nif (SNP.SOURCE == \"hapmap\") {\n  thresh <- max(BAF.THRESH, 1 - BAF.SD * sd(tbaf[tbaf > BAF.THRESH]))\n  bok <- abs(tbaf-0.5) < thresh/2\n} else {\n  bok <- rep(T, length(tbaf))\n}\n\ntbaf <- tbaf[bok]\n\n# check :  lx.plot(tbaf)\n\n# get probe copy number for each SNP\n\ncpos <- snp$COORD[bok]\nipos <- match(snp$PROBE[bok], df$indx)\nfok  <- ! is.na(ipos)\nipos <- ipos[fok]\ncpos <- cpos[fok]\n\ntrrc <- tcov[ipos]/(mcov[ipos] + RATIO.EPS)\n\nchrs <- coords2clocs(tdat, cpos)[,1]\n\ndff <- data.frame(x=cpos, rrc=trrc, baf=tbaf[fok],  chrs=chrs)\n\n# ---------------------\n# make ploidy model\n# \n\nsegsize <- nrow(dff) * MIN.SEGSIZE / 3e9\n\n# \n# pre-segmentation using BCP\n#\nssegs <- asdog.bcp.segment(dff$rrc, dff$baf, \n                           rcmax=RRC.MAX,\n                           smooth.rc=NULL, smooth.af=NULL,\n                           p0=BCP.P0,\n                           sample.size=nrow(dff),\n                           minseg.size=segsize)$seg\n\n#\n# fit ploidy model\n# - threshold segment size\n# - fit model\n#\n\nobs <- ssegs[,1,drop=F]\nobs$rc <- ssegs$mean.rc\nobs$af <- ssegs$mean.af\nobs$weight <- log10(ssegs$weight)\nobs <- obs[,-1]\n\n# threshold weights\n\nquant <- quantile(obs$weight, WEIGHT.QUANT)\nobs <- obs[obs$weight >= quant,,drop=F]\n\n# fit ploidy model\n\nlx.out(\"fitting ploidy model\", with.mem=T)\n\nplfit <- plmodel.fit(obs,\n                   min.A=RANGE.A[1],\n                   max.A=RANGE.A[2],\n                   step.A=RANGE.A[3],\n                   min.Q=RANGE.Q[1],\n                   max.Q=RANGE.Q[2],\n                   step.Q=RANGE.Q[3],\n                   theo.weight=F,\n                   gamma0=FIT.GAMMA0,\n                   rho=FIT.RHO)\n\nlx.out(\"best model alpha=\", plfit$a0, \" Q=\", plfit$q0)\n\npltheo <- asdog.theo.RCAF(plfit$a0, plfit$q0, qrange=0:CN.MAX)\n\n# ---------------------\n# final HMM segmentation\n#\n# note: segment all chromosomes at once\n#       not chr by chr as in asdog\n#\n\nmax.theo.rc <- max(pltheo$rc)\n\n.c <- function(x,y=x) complex(real=x, imaginary=y)\n\nmeans <- .c(pltheo$rc, pltheo$af-0.5)\nsd.rc <- lx.wt.mean(ssegs$sd.rc, ssegs$weight)\nsd.af <- lx.wt.mean(ssegs$sd.af, ssegs$weight)\nsds <- .c(sd.rc, sd.af)\n\nhmm <- thmm.init(drcaf.asdog, HMM.TAU,\n                 mean=means,\n                 sd=sds)\n\nrrc <- dff$rrc\nrrc <- lx.smooth.median(dff$rrc, c(3,5,15)) #####\nbaf <- dff$baf\npos <- dff$x\n\nrrc[rrc >= max.theo.rc] <- max.theo.rc\n\nvit <- thmm.viterbi(hmm, .c(rrc, baf-0.5))\n\nrle <- rle(vit$states)\nifrom <- head(c(0, cumsum(rle$lengths)) + 1, -1)\ncoords <- cbind(pos[ifrom], pos[ifrom+rle$lengths-1])\n\n# we should cut at chrs boundaries... this is a pain in the neck...\nintb <- intervals::Intervals(basta2coords(tdat))\nintc <- intervals::Intervals(coords)\nintr <- intervals::interval_intersection(intb, intc)\nclocs <- coords2clocs(tdat, intr)\nipos <- findInterval(intr[,1], intc[,1])\nvals <- rle$values[ipos[seq_len(nrow(intr))]]\n\n# make final segments\nfsegs <- data.frame(cfrom=intr[,1], cto=intr[,2], clocs)\n\nfsegs$state <- vals\nfsegs$rc <- pltheo$rc[vals]\nfsegs$af <- pltheo$af[vals]\nfsegs$ploidy <- pltheo$ploidy[vals]\nfsegs$geno <- pltheo$label[vals]\n\n# and add some statistics\nstat.rc <- stat.segments(fsegs, dff$x, dff$rrc, \"rc\")\nnb.mark <- stat.rc[,1]\nstat.rc <- stat.rc[,-1]\ncolnames(stat.rc) <- paste(colnames(stat.rc), \"rrc\", sep=\".\")\nstat.af <- stat.segments(fsegs, dff$x, dff$baf, \"af\")[,-1]\ncolnames(stat.af) <- paste(colnames(stat.af), \"baf\", sep=\".\")\nppm.mark <- nb.mark / (fsegs$to - fsegs$from + 1) * 1e6\nfsegs <- cbind(fsegs, nb.mark=nb.mark, ppm.mark=ppm.mark, stat.rc, stat.af)\n\n\n# ---------------------\n# reporting\n#\n\nbase <- lx.strsplit(basename(tfil), \"\\\\.\")[1]\n\n#\n# plots\n#\n\nasdog.tex.driver(list(report.latex.driver=\"jpeg\", report.driver.res=300))\n\ntex <- tex.open(base)\n\ntex.section(tex, \"GC Model\")\n\n# fig on\n#\ntex <- tex.fig.on(tex, width=7, height=4, family=\"Times\")\npar(mfrow=c(1,2))\nplot.gcmodel(nmod.gc)\ntitle(\"GC model Normal\")\nplot.gcmodel(tmod.gc)\ntitle(\"GC model Tumor\")\npar(mfrow=c(1,1))\ntex <- tex.fig.off(tex)\n#\n# fig off\n\ntex.tag(tex, \"newpage\")\ntex.section(tex, \"Ploidy Fit\")\ntex.subsection(tex, \"Alpha-Q fit\")\n# fig on\n#\ntex <- tex.fig.on(tex, width=4, height=4, family=\"Times\")\nasdog.plot.plmodel.fit(plfit)\ntex <- tex.fig.off(tex)\n#\n# fig off\n\ntex.subsection(tex, \"CN-AF fit\")\n# fig on\n#\ntex <- tex.fig.on(tex, width=4, height=4, family=\"Times\")\nasdog.plot.plmodel.rcaf(obs, pltheo)\ntitle(paste0(\"a=\", round(plfit$a0, 2), \n             \" Q=\", round(plfit$q0, 2),\n             \" qual=\", round(plfit$qual*100, 1), \"%\"))\ntex <- tex.fig.off(tex)\n#\n# fig off\n\n\ntex.tag(tex, \"newpage\")\ntex.section(tex, \"CN-AF Profiles\")    \n# fig on\n#\ntex <- tex.fig.on(tex, width=7, height=7, family=\"Times\")\nopar <- par(no.readonly=T)\npar(mfrow=c(2, 1),\n    mgp=c(2,1,0),\n    mar=c(0, 4, 0, 2) + 0.1,\n    oma=c(4, 0, 2, 0) + 0.1)\n\nplot.profile(dff$x, dff$rrc, ylim=c(0, RRC.MAX), ylab=\"rrc\", alpha=0, xaxt='n')\npal.qual <- viridis::viridis(11, alpha=0.5)\ncol.qual <- rev(pal.qual)[round(pmin(10, pmax(0, abs(fsegs$zscor.rrc)))) + 1]\nsegments(fsegs$cfrom, 0, fsegs$cto, 0, col=col.qual, lwd=1000, lend=1)\nplot.profile(dff$x, dff$rrc, fun=points, ylim=c(0, RRC.MAX),\n             chrs=dff$chrs, alpha=0.8, xaxt='n')\nabline(h=unique(Re(thmm.parameters(hmm, \"mean\"))), lty=2, lwd=0.5, col=lx.GREY)\nsegments(dff$x[ssegs$pfrom], ssegs$mean.rc,\n         dff$x[ssegs$pto], ssegs$mean.rc,\n         col=lx.color.alpha(7, 0.5), lwd=5)\nsegments(fsegs$cfrom, fsegs$rc, fsegs$cto, fsegs$rc, col=2, lwd=3)\naxis(4, pltheo$rc, pltheo$ploidy, las=2, cex.axis=0.5)\n\n\nplot.profile(dff$x, dff$baf, ylim=c(0,1), ylab=\"af\", alpha=0, hline=0.5)\ncol.qual <- rev(pal.qual)[round(pmin(10, pmax(0, abs(fsegs$zscor.baf)))) + 1]\nsegments(fsegs$cfrom, 0.5, fsegs$cto, 0.5, col=col.qual, lwd=1000, lend=1)\nplot.profile(dff$x, dff$baf, fun=points, ylim=c(0,1), chrs=dff$chrs, hline=0.5, alpha=0.8)\n#abline(h=unique(Im(thmm.parameters(hmm, \"mean\")))+0.5, lty=2, lwd=0.5)\nsegments(dff$x[ssegs$pfrom], ssegs$mean.af, \n         dff$x[ssegs$pto], ssegs$mean.af,\n         col=lx.color.alpha(7, 0.5), lwd=5)\nsegments(fsegs$cfrom, fsegs$af, fsegs$cto, fsegs$af, col=2, lwd=3)\npar(opar)\ntex <- tex.fig.off(tex)\n#\n# fig off\n\ntex <- tex.close(tex)\n\n#\n# segments\n#\n\nout <- fsegs[,-(1:2)]\n\ntyps <- sapply(out, typeof)\nfor (coln in setdiff(names(typs[typs==\"double\"]), c(\"nb.mark\", \"pval.rc\", \"pval.af\"))) {\n  out[,coln] <- round(out[,coln], 3)\n}\nfor (coln in c(\"pval.rc\", \"pval.af\")) {\n  out[,coln] <- sprintf(\"%.2e\", out[,coln])\n}\n\nwrite.table(out, paste0(base, \".segments.txt\"), quote=F)\n\n} \n\n\n\n\n\n",
    "created" : 1505521214653.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2588492905",
    "id" : "B402B6D1",
    "lastKnownWriteTime" : 1511164866,
    "last_content_update" : 1511164866985,
    "path" : "~/Developpements/SvnProjects/WGInR_Asdog/Rsrc/scripts/aspup.main.r",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 10,
    "source_on_save" : true,
    "source_window" : "",
    "type" : "r_source"
}